{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32b08805-3341-47e6-8b5b-bed7f086336f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Time : 20-6-4 下午6:18\n",
    "# @Author : zhuying\n",
    "# @Company : Minivision\n",
    "# @File : functional.py\n",
    "# @Software : PyCharm\n",
    "\n",
    "from __future__ import division\n",
    "import torch\n",
    "from PIL import Image, ImageOps, ImageEnhance\n",
    "try:\n",
    "    import accimage\n",
    "except ImportError:\n",
    "    accimage = None\n",
    "import numpy as np\n",
    "import numbers\n",
    "import types\n",
    "import collections\n",
    "import warnings\n",
    "\n",
    "\n",
    "def _is_pil_image(img):\n",
    "    if accimage is not None:\n",
    "        return isinstance(img, (Image.Image, accimage.Image))\n",
    "    else:\n",
    "        return isinstance(img, Image.Image)\n",
    "\n",
    "\n",
    "def _is_tensor_image(img):\n",
    "    return torch.is_tensor(img) and img.ndimension() == 3\n",
    "\n",
    "\n",
    "def _is_numpy_image(img):\n",
    "    return isinstance(img, np.ndarray) and (img.ndim in {2, 3})\n",
    "\n",
    "\n",
    "def to_tensor(pic):\n",
    "    \"\"\"Convert a ``PIL Image`` or ``numpy.ndarray`` to tensor.\n",
    "\n",
    "    See ``ToTensor`` for more details.\n",
    "\n",
    "    Args:\n",
    "        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Converted image.\n",
    "    \"\"\"\n",
    "    if not(_is_pil_image(pic) or _is_numpy_image(pic)):\n",
    "        raise TypeError('pic should be PIL Image or ndarray. Got {}'.format(type(pic)))\n",
    "\n",
    "    if isinstance(pic, np.ndarray):\n",
    "        # handle numpy array\n",
    "        # IR image channel=1: modify by lzc --> 20190730\n",
    "        if pic.ndim == 2:\n",
    "            pic = pic.reshape((pic.shape[0], pic.shape[1], 1))\n",
    "\n",
    "        img = torch.from_numpy(pic.transpose((2, 0, 1)))\n",
    "        # backward compatibility\n",
    "        # return img.float().div(255)  modify by zkx\n",
    "        return img.float()\n",
    "    if accimage is not None and isinstance(pic, accimage.Image):\n",
    "        nppic = np.zeros([pic.channels, pic.height, pic.width], dtype=np.float32)\n",
    "        pic.copyto(nppic)\n",
    "        return torch.from_numpy(nppic)\n",
    "\n",
    "    # handle PIL Image\n",
    "    if pic.mode == 'I':\n",
    "        img = torch.from_numpy(np.array(pic, np.int32, copy=False))\n",
    "    elif pic.mode == 'I;16':\n",
    "        img = torch.from_numpy(np.array(pic, np.int16, copy=False))\n",
    "    else:\n",
    "        img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
    "    # PIL image mode: 1, L, P, I, F, RGB, YCbCr, RGBA, CMYK\n",
    "    if pic.mode == 'YCbCr':\n",
    "        nchannel = 3\n",
    "    elif pic.mode == 'I;16':\n",
    "        nchannel = 1\n",
    "    else:\n",
    "        nchannel = len(pic.mode)\n",
    "    img = img.view(pic.size[1], pic.size[0], nchannel)\n",
    "    # put it from HWC to CHW format\n",
    "    # yikes, this transpose takes 80% of the loading time/CPU\n",
    "    img = img.transpose(0, 1).transpose(0, 2).contiguous()\n",
    "    if isinstance(img, torch.ByteTensor):\n",
    "        # return img.float().div(255)  #modified by zkx\n",
    "        return img.float()\n",
    "    else:\n",
    "        return img\n",
    "\n",
    "\n",
    "def to_pil_image(pic, mode=None):\n",
    "    \"\"\"Convert a tensor or an ndarray to PIL Image.\n",
    "\n",
    "    See :class:`~torchvision.transforms.ToPIlImage` for more details.\n",
    "\n",
    "    Args:\n",
    "        pic (Tensor or numpy.ndarray): Image to be converted to PIL Image.\n",
    "        mode (`PIL.Image mode`_): color space and pixel depth of input data (optional).\n",
    "\n",
    "    .. _PIL.Image mode: http://pillow.readthedocs.io/en/3.4.x/handbook/concepts.html#modes\n",
    "\n",
    "    Returns:\n",
    "        PIL Image: Image converted to PIL Image.\n",
    "    \"\"\"\n",
    "    if not(_is_numpy_image(pic) or _is_tensor_image(pic)):\n",
    "        raise TypeError('pic should be Tensor or ndarray. Got {}.'.format(type(pic)))\n",
    "\n",
    "    npimg = pic\n",
    "    if isinstance(pic, torch.FloatTensor):\n",
    "        pic = pic.mul(255).byte()\n",
    "    if torch.is_tensor(pic):\n",
    "        npimg = np.transpose(pic.numpy(), (1, 2, 0))\n",
    "\n",
    "    if not isinstance(npimg, np.ndarray):\n",
    "        raise TypeError('Input pic must be a torch.Tensor or NumPy ndarray, ' +\n",
    "                        'not {}'.format(type(npimg)))\n",
    "\n",
    "    if npimg.shape[2] == 1:\n",
    "        expected_mode = None\n",
    "        npimg = npimg[:, :, 0]\n",
    "        if npimg.dtype == np.uint8:\n",
    "            expected_mode = 'L'\n",
    "        if npimg.dtype == np.int16:\n",
    "            expected_mode = 'I;16'\n",
    "        if npimg.dtype == np.int32:\n",
    "            expected_mode = 'I'\n",
    "        elif npimg.dtype == np.float32:\n",
    "            expected_mode = 'F'\n",
    "        if mode is not None and mode != expected_mode:\n",
    "            raise ValueError(\"Incorrect mode ({}) supplied for input type {}. Should be {}\"\n",
    "                             .format(mode, np.dtype, expected_mode))\n",
    "        mode = expected_mode\n",
    "\n",
    "    elif npimg.shape[2] == 4:\n",
    "        permitted_4_channel_modes = ['RGBA', 'CMYK']\n",
    "        if mode is not None and mode not in permitted_4_channel_modes:\n",
    "            raise ValueError(\"Only modes {} are supported for 4D inputs\".format(permitted_4_channel_modes))\n",
    "\n",
    "        if mode is None and npimg.dtype == np.uint8:\n",
    "            mode = 'RGBA'\n",
    "    else:\n",
    "        permitted_3_channel_modes = ['RGB', 'YCbCr', 'HSV']\n",
    "        if mode is not None and mode not in permitted_3_channel_modes:\n",
    "            raise ValueError(\"Only modes {} are supported for 3D inputs\".format(permitted_3_channel_modes))\n",
    "        if mode is None and npimg.dtype == np.uint8:\n",
    "            mode = 'RGB'\n",
    "\n",
    "    if mode is None:\n",
    "        raise TypeError('Input type {} is not supported'.format(npimg.dtype))\n",
    "\n",
    "    return Image.fromarray(npimg, mode=mode)\n",
    "\n",
    "\n",
    "def normalize(tensor, mean, std):\n",
    "    \"\"\"Normalize a tensor image with mean and standard deviation.\n",
    "\n",
    "    See ``Normalize`` for more details.\n",
    "\n",
    "    Args:\n",
    "        tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "        mean (sequence): Sequence of means for each channel.\n",
    "        std (sequence): Sequence of standard deviations for each channely.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Normalized Tensor image.\n",
    "    \"\"\"\n",
    "    if not _is_tensor_image(tensor):\n",
    "        raise TypeError('tensor is not a torch image.')\n",
    "\n",
    "    for t, m, s in zip(tensor, mean, std):\n",
    "        t.sub_(m).div_(s)\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def resize(img, size, interpolation=Image.BILINEAR):\n",
    "    \"\"\"Resize the input PIL Image to the given size.\n",
    "\n",
    "    Args:\n",
    "        img (PIL Image): Image to be resized.\n",
    "        size (sequence or int): Desired output size. If size is a sequence like\n",
    "            (h, w), the output size will be matched to this. If size is an int,\n",
    "            the smaller edge of the image will be matched to this number maintaing\n",
    "            the aspect ratio. i.e, if height > width, then image will be rescaled to\n",
    "            (size * height / width, size)\n",
    "        interpolation (int, optional): Desired interpolation. Default is\n",
    "            ``PIL.Image.BILINEAR``\n",
    "\n",
    "    Returns:\n",
    "        PIL Image: Resized image.\n",
    "    \"\"\"\n",
    "    if not _is_pil_image(img):\n",
    "        raise TypeError('img should be PIL Image. Got {}'.format(type(img)))\n",
    "    if not (isinstance(size, int) or (isinstance(size, collections.Iterable) and len(size) == 2)):\n",
    "        raise TypeError('Got inappropriate size arg: {}'.format(size))\n",
    "\n",
    "    if isinstance(size, int):\n",
    "        w, h = img.size\n",
    "        if (w <= h and w == size) or (h <= w and h == size):\n",
    "            return img\n",
    "        if w < h:\n",
    "            ow = size\n",
    "            oh = int(size * h / w)\n",
    "            return img.resize((ow, oh), interpolation)\n",
    "        else:\n",
    "            oh = size\n",
    "            ow = int(size * w / h)\n",
    "            return img.resize((ow, oh), interpolation)\n",
    "    else:\n",
    "        return img.resize(size[::-1], interpolation)\n",
    "\n",
    "\n",
    "def scale(*args, **kwargs):\n",
    "    warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\n",
    "                  \"please use transforms.Resize instead.\")\n",
    "    return resize(*args, **kwargs)\n",
    "\n",
    "\n",
    "def pad(img, padding, fill=0):\n",
    "    \"\"\"Pad the given PIL Image on all sides with the given \"pad\" value.\n",
    "\n",
    "    Args:\n",
    "        img (PIL Image): Image to be padded.\n",
    "        padding (int or tuple): Padding on each border. If a single int is provided this\n",
    "            is used to pad all borders. If tuple of length 2 is provided this is the padding\n",
    "            on left/right and top/bottom respectively. If a tuple of length 4 is provided\n",
    "            this is the padding for the left, top, right and bottom borders\n",
    "            respectively.\n",
    "        fill: Pixel fill value. Default is 0. If a tuple of\n",
    "            length 3, it is used to fill R, G, B channels respectively.\n",
    "\n",
    "    Returns:\n",
    "        PIL Image: Padded image.\n",
    "    \"\"\"\n",
    "    if not _is_pil_image(img):\n",
    "        raise TypeError('img should be PIL Image. Got {}'.format(type(img)))\n",
    "\n",
    "    if not isinstance(padding, (numbers.Number, tuple)):\n",
    "        raise TypeError('Got inappropriate padding arg')\n",
    "    if not isinstance(fill, (numbers.Number, str, tuple)):\n",
    "        raise TypeError('Got inappropriate fill arg')\n",
    "\n",
    "    if isinstance(padding, collections.Sequence) and len(padding) not in [2, 4]:\n",
    "        raise ValueError(\"Padding must be an int or a 2, or 4 element tuple, not a \" +\n",
    "                         \"{} element tuple\".format(len(padding)))\n",
    "\n",
    "    return ImageOps.expand(img, border=padding, fill=fill)\n",
    "\n",
    "\n",
    "def crop(img, i, j, h, w):\n",
    "    \"\"\"Crop the given PIL Image.\n",
    "\n",
    "    Args:\n",
    "        img (PIL Image): Image to be cropped.\n",
    "        i: Upper pixel coordinate.\n",
    "        j: Left pixel coordinate.\n",
    "        h: Height of the cropped image.\n",
    "        w: Width of the cropped image.\n",
    "\n",
    "    Returns:\n",
    "        PIL Image: Cropped image.\n",
    "    \"\"\"\n",
    "    if not _is_pil_image(img):\n",
    "        raise TypeError('img should be PIL Image. Got {}'.format(type(img)))\n",
    "\n",
    "    return img.crop((j, i, j + w, i + h))\n",
    "\n",
    "\n",
    "def center_crop(img, output_size):\n",
    "    if isinstance(output_size, numbers.Number):\n",
    "        output_size = (int(output_size), int(output_size))\n",
    "    w, h = img.size\n",
    "    th, tw = output_size\n",
    "    i = int(round((h - th) / 2.))\n",
    "    j = int(round((w - tw) / 2.))\n",
    "    return crop(img, i, j, th, tw)\n",
    "\n",
    "\n",
    "def resized_crop(img, i, j, h, w, size, interpolation=Image.BILINEAR):\n",
    "    \"\"\"Crop the given PIL Image and resize it to desired size.\n",
    "\n",
    "    Notably used in RandomResizedCrop.\n",
    "\n",
    "    Args:\n",
    "        img (PIL Image): Image to be cropped.\n",
    "        i: Upper pixel coordinate.\n",
    "        j: Left pixel coordinate.\n",
    "        h: Height of the cropped image.\n",
    "        w: Width of the cropped image.\n",
    "        size (sequence or int): Desired output size. Same semantics as ``scale``.\n",
    "        interpolation (int, optional): Desired interpolation. Default is\n",
    "            ``PIL.Image.BILINEAR``.\n",
    "    Returns:\n",
    "        PIL Image: Cropped image.\n",
    "    \"\"\"\n",
    "    assert _is_pil_image(img), 'img should be PIL Image'\n",
    "    img = crop(img, i, j, h, w)\n",
    "    img = resize(img, size, interpolation)\n",
    "    return img\n",
    "\n",
    "\n",
    "def hflip(img):\n",
    "    \"\"\"Horizontally flip the given PIL Image.\n",
    "\n",
    "    Args:\n",
    "        img (PIL Image): Image to be flipped.\n",
    "\n",
    "    Returns:\n",
    "        PIL Image:  Horizontall flipped image.\n",
    "    \"\"\"\n",
    "    if not _is_pil_image(img):\n",
    "        raise TypeError('img should be PIL Image. Got {}'.format(type(img)))\n",
    "\n",
    "    return img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "\n",
    "def vflip(img):\n",
    "    \"\"\"Vertically flip the given PIL Image.\n",
    "\n",
    "    Args:\n",
    "        img (PIL Image): Image to be flipped.\n",
    "\n",
    "    Returns:\n",
    "        PIL Image:  Vertically flipped image.\n",
    "    \"\"\"\n",
    "    if not _is_pil_image(img):\n",
    "        raise TypeError('img should be PIL Image. Got {}'.format(type(img)))\n",
    "\n",
    "    return img.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "\n",
    "\n",
    "def five_crop(img, size):\n",
    "    \"\"\"Crop the given PIL Image into four corners and the central crop.\n",
    "\n",
    "    .. Note::\n",
    "        This transform returns a tuple of images and there may be a\n",
    "        mismatch in the number of inputs and targets your ``Dataset`` returns.\n",
    "\n",
    "    Args:\n",
    "       size (sequence or int): Desired output size of the crop. If size is an\n",
    "           int instead of sequence like (h, w), a square crop (size, size) is\n",
    "           made.\n",
    "    Returns:\n",
    "        tuple: tuple (tl, tr, bl, br, center) corresponding top left,\n",
    "            top right, bottom left, bottom right and center crop.\n",
    "    \"\"\"\n",
    "    if isinstance(size, numbers.Number):\n",
    "        size = (int(size), int(size))\n",
    "    else:\n",
    "        assert len(size) == 2, \"Please provide only two dimensions (h, w) for size.\"\n",
    "\n",
    "    w, h = img.size\n",
    "    crop_h, crop_w = size\n",
    "    if crop_w > w or crop_h > h:\n",
    "        raise ValueError(\"Requested crop size {} is bigger than input size {}\".format(size,\n",
    "                                                                                      (h, w)))\n",
    "    tl = img.crop((0, 0, crop_w, crop_h))\n",
    "    tr = img.crop((w - crop_w, 0, w, crop_h))\n",
    "    bl = img.crop((0, h - crop_h, crop_w, h))\n",
    "    br = img.crop((w - crop_w, h - crop_h, w, h))\n",
    "    center = center_crop(img, (crop_h, crop_w))\n",
    "    return (tl, tr, bl, br, center)\n",
    "\n",
    "\n",
    "def ten_crop(img, size, vertical_flip=False):\n",
    "    \"\"\"Crop the given PIL Image into four corners and the central crop plus the\n",
    "       flipped version of these (horizontal flipping is used by default).\n",
    "\n",
    "    .. Note::\n",
    "        This transform returns a tuple of images and there may be a\n",
    "        mismatch in the number of inputs and targets your ``Dataset`` returns.\n",
    "\n",
    "       Args:\n",
    "           size (sequence or int): Desired output size of the crop. If size is an\n",
    "               int instead of sequence like (h, w), a square crop (size, size) is\n",
    "               made.\n",
    "           vertical_flip (bool): Use vertical flipping instead of horizontal\n",
    "\n",
    "        Returns:\n",
    "            tuple: tuple (tl, tr, bl, br, center, tl_flip, tr_flip, bl_flip,\n",
    "                br_flip, center_flip) corresponding top left, top right,\n",
    "                bottom left, bottom right and center crop and same for the\n",
    "                flipped image.\n",
    "    \"\"\"\n",
    "    if isinstance(size, numbers.Number):\n",
    "        size = (int(size), int(size))\n",
    "    else:\n",
    "        assert len(size) == 2, \"Please provide only two dimensions (h, w) for size.\"\n",
    "\n",
    "    first_five = five_crop(img, size)\n",
    "\n",
    "    if vertical_flip:\n",
    "        img = vflip(img)\n",
    "    else:\n",
    "        img = hflip(img)\n",
    "\n",
    "    second_five = five_crop(img, size)\n",
    "    return first_five + second_five\n",
    "\n",
    "\n",
    "def adjust_brightness(img, brightness_factor):\n",
    "    \"\"\"Adjust brightness of an Image.\n",
    "\n",
    "    Args:\n",
    "        img (PIL Image): PIL Image to be adjusted.\n",
    "        brightness_factor (float):  How much to adjust the brightness. Can be\n",
    "            any non negative number. 0 gives a black image, 1 gives the\n",
    "            original image while 2 increases the brightness by a factor of 2.\n",
    "\n",
    "    Returns:\n",
    "        PIL Image: Brightness adjusted image.\n",
    "    \"\"\"\n",
    "    if not _is_pil_image(img):\n",
    "        raise TypeError('img should be PIL Image. Got {}'.format(type(img)))\n",
    "\n",
    "    enhancer = ImageEnhance.Brightness(img)\n",
    "    img = enhancer.enhance(brightness_factor)\n",
    "    return img\n",
    "\n",
    "\n",
    "def adjust_contrast(img, contrast_factor):\n",
    "    \"\"\"Adjust contrast of an Image.\n",
    "\n",
    "    Args:\n",
    "        img (PIL Image): PIL Image to be adjusted.\n",
    "        contrast_factor (float): How much to adjust the contrast. Can be any\n",
    "            non negative number. 0 gives a solid gray image, 1 gives the\n",
    "            original image while 2 increases the contrast by a factor of 2.\n",
    "\n",
    "    Returns:\n",
    "        PIL Image: Contrast adjusted image.\n",
    "    \"\"\"\n",
    "    if not _is_pil_image(img):\n",
    "        raise TypeError('img should be PIL Image. Got {}'.format(type(img)))\n",
    "\n",
    "    enhancer = ImageEnhance.Contrast(img)\n",
    "    img = enhancer.enhance(contrast_factor)\n",
    "    return img\n",
    "\n",
    "\n",
    "def adjust_saturation(img, saturation_factor):\n",
    "    \"\"\"Adjust color saturation of an image.\n",
    "\n",
    "    Args:\n",
    "        img (PIL Image): PIL Image to be adjusted.\n",
    "        saturation_factor (float):  How much to adjust the saturation. 0 will\n",
    "            give a black and white image, 1 will give the original image while\n",
    "            2 will enhance the saturation by a factor of 2.\n",
    "\n",
    "    Returns:\n",
    "        PIL Image: Saturation adjusted image.\n",
    "    \"\"\"\n",
    "    if not _is_pil_image(img):\n",
    "        raise TypeError('img should be PIL Image. Got {}'.format(type(img)))\n",
    "\n",
    "    enhancer = ImageEnhance.Color(img)\n",
    "    img = enhancer.enhance(saturation_factor)\n",
    "    return img\n",
    "\n",
    "\n",
    "def adjust_hue(img, hue_factor):\n",
    "    \"\"\"Adjust hue of an image.\n",
    "\n",
    "    The image hue is adjusted by converting the image to HSV and\n",
    "    cyclically shifting the intensities in the hue channel (H).\n",
    "    The image is then converted back to original image mode.\n",
    "\n",
    "    `hue_factor` is the amount of shift in H channel and must be in the\n",
    "    interval `[-0.5, 0.5]`.\n",
    "\n",
    "    See https://en.wikipedia.org/wiki/Hue for more details on Hue.\n",
    "\n",
    "    Args:\n",
    "        img (PIL Image): PIL Image to be adjusted.\n",
    "        hue_factor (float):  How much to shift the hue channel. Should be in\n",
    "            [-0.5, 0.5]. 0.5 and -0.5 give complete reversal of hue channel in\n",
    "            HSV space in positive and negative direction respectively.\n",
    "            0 means no shift. Therefore, both -0.5 and 0.5 will give an image\n",
    "            with complementary colors while 0 gives the original image.\n",
    "\n",
    "    Returns:\n",
    "        PIL Image: Hue adjusted image.\n",
    "    \"\"\"\n",
    "    if not(-0.5 <= hue_factor <= 0.5):\n",
    "        raise ValueError('hue_factor is not in [-0.5, 0.5].'.format(hue_factor))\n",
    "\n",
    "    if not _is_pil_image(img):\n",
    "        raise TypeError('img should be PIL Image. Got {}'.format(type(img)))\n",
    "\n",
    "    input_mode = img.mode\n",
    "    if input_mode in {'L', '1', 'I', 'F'}:\n",
    "        return img\n",
    "\n",
    "    h, s, v = img.convert('HSV').split()\n",
    "\n",
    "    np_h = np.array(h, dtype=np.uint8)\n",
    "    # uint8 addition take cares of rotation across boundaries\n",
    "    with np.errstate(over='ignore'):\n",
    "        np_h += np.uint8(hue_factor * 255)\n",
    "    h = Image.fromarray(np_h, 'L')\n",
    "\n",
    "    img = Image.merge('HSV', (h, s, v)).convert(input_mode)\n",
    "    return img\n",
    "\n",
    "\n",
    "def adjust_gamma(img, gamma, gain=1):\n",
    "    \"\"\"Perform gamma correction on an image.\n",
    "\n",
    "    Also known as Power Law Transform. Intensities in RGB mode are adjusted\n",
    "    based on the following equation:\n",
    "\n",
    "        I_out = 255 * gain * ((I_in / 255) ** gamma)\n",
    "\n",
    "    See https://en.wikipedia.org/wiki/Gamma_correction for more details.\n",
    "\n",
    "    Args:\n",
    "        img (PIL Image): PIL Image to be adjusted.\n",
    "        gamma (float): Non negative real number. gamma larger than 1 make the\n",
    "            shadows darker, while gamma smaller than 1 make dark regions\n",
    "            lighter.\n",
    "        gain (float): The constant multiplier.\n",
    "    \"\"\"\n",
    "    if not _is_pil_image(img):\n",
    "        raise TypeError('img should be PIL Image. Got {}'.format(type(img)))\n",
    "\n",
    "    if gamma < 0:\n",
    "        raise ValueError('Gamma should be a non-negative real number')\n",
    "\n",
    "    input_mode = img.mode\n",
    "    img = img.convert('RGB')\n",
    "\n",
    "    np_img = np.array(img, dtype=np.float32)\n",
    "    np_img = 255 * gain * ((np_img / 255) ** gamma)\n",
    "    np_img = np.uint8(np.clip(np_img, 0, 255))\n",
    "\n",
    "    img = Image.fromarray(np_img, 'RGB').convert(input_mode)\n",
    "    return img\n",
    "\n",
    "\n",
    "def rotate(img, angle, resample=False, expand=False, center=None):\n",
    "    \"\"\"Rotate the image by angle and then (optionally) translate it by (n_columns, n_rows)\n",
    "\n",
    "\n",
    "    Args:\n",
    "        img (PIL Image): PIL Image to be rotated.\n",
    "        angle ({float, int}): In degrees degrees counter clockwise order.\n",
    "        resample ({PIL.Image.NEAREST, PIL.Image.BILINEAR, PIL.Image.BICUBIC}, optional):\n",
    "            An optional resampling filter.\n",
    "            See http://pillow.readthedocs.io/en/3.4.x/handbook/concepts.html#filters\n",
    "            If omitted, or if the image has mode \"1\" or \"P\", it is set to PIL.Image.NEAREST.\n",
    "        expand (bool, optional): Optional expansion flag.\n",
    "            If true, expands the output image to make it large enough to hold the entire rotated image.\n",
    "            If false or omitted, make the output image the same size as the input image.\n",
    "            Note that the expand flag assumes rotation around the center and no translation.\n",
    "        center (2-tuple, optional): Optional center of rotation.\n",
    "            Origin is the upper left corner.\n",
    "            Default is the center of the image.\n",
    "    \"\"\"\n",
    "\n",
    "    if not _is_pil_image(img):\n",
    "        raise TypeError('img should be PIL Image. Got {}'.format(type(img)))\n",
    "\n",
    "    return img.rotate(angle, resample, expand, center)\n",
    "\n",
    "\n",
    "def to_grayscale(img, num_output_channels=1):\n",
    "    \"\"\"Convert image to grayscale version of image.\n",
    "\n",
    "    Args:\n",
    "        img (PIL Image): Image to be converted to grayscale.\n",
    "\n",
    "    Returns:\n",
    "        PIL Image:  Grayscale version of the image.\n",
    "                    if num_output_channels == 1 : returned image is single channel\n",
    "                    if num_output_channels == 3 : returned image is 3 channel with r == g == b\n",
    "    \"\"\"\n",
    "    if not _is_pil_image(img):\n",
    "        raise TypeError('img should be PIL Image. Got {}'.format(type(img)))\n",
    "\n",
    "    if num_output_channels == 1:\n",
    "        img = img.convert('L')\n",
    "    elif num_output_channels == 3:\n",
    "        img = img.convert('L')\n",
    "        np_img = np.array(img, dtype=np.uint8)\n",
    "        np_img = np.dstack([np_img, np_img, np_img])\n",
    "        img = Image.fromarray(np_img, 'RGB')\n",
    "    else:\n",
    "        raise ValueError('num_output_channels should be either 1 or 3')\n",
    "\n",
    "    return img"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
